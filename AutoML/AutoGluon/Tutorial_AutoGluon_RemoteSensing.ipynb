{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_AutoGluon_RemoteSensing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/ozkVlSuzJJp/0tk/714a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunocesarsa/Examples/blob/main/AutoML/AutoGluon/Tutorial_AutoGluon_RemoteSensing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6HVuggKN4fk"
      },
      "source": [
        "# AutoGluon\r\n",
        "\r\n",
        "Is an autoML approach proposed recently by an AWS team. https://auto.gluon.ai/stable/index.html\r\n",
        "\r\n",
        "\r\n",
        "*   https://hangzhang.org/CVPR2020/\r\n",
        "*   https://jwmueller.github.io/KDD20-tutorial/\r\n",
        "*   Reference paper: https://arxiv.org/abs/2003.06505\r\n",
        "\r\n",
        "# Choose Runtime - GPU\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6fmkqzHNFqo"
      },
      "source": [
        "# Here we assume CUDA 10.0 is installed.  You should change the number\r\n",
        "# according to your own CUDA version (e.g. mxnet-cu101 for CUDA 10.1).\r\n",
        "!pip uninstall -y mkl\r\n",
        "!pip install --upgrade mxnet-cu100\r\n",
        "!pip install autogluon\r\n",
        "\r\n",
        "!pip install -U ipykernel\r\n",
        "\r\n",
        "!pip install -U dask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28iBXLv1ON48"
      },
      "source": [
        "#Testing AutoGluon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl8QRi9SOM4V"
      },
      "source": [
        "from autogluon import TabularPrediction as task\r\n",
        "train_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\r\n",
        "test_data = task.Dataset(file_path='https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\r\n",
        "predictor = task.fit(train_data=train_data, label='class')\r\n",
        "performance = predictor.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-gcxj14RUIP"
      },
      "source": [
        "#Fetching the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMTnQP7HS6Hn"
      },
      "source": [
        "## Downloading\r\n",
        "\r\n",
        "The data is \"stolen\" from this excellent tutorial on how to do a classification with R:\r\n",
        "\r\n",
        "*   https://urbanspatial.github.io/classifying_satellite_imagery_in_R/\r\n",
        "*   https://github.com/urbanSpatial/classifying_satellite_imagery_in_R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxl-YHMMSo4h",
        "outputId": "2d3b4e67-1b70-4655-cc1c-a5e380a2daa9"
      },
      "source": [
        "!git clone https://github.com/urbanSpatial/classifying_satellite_imagery_in_R"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'classifying_satellite_imagery_in_R'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 106 (delta 2), reused 23 (delta 2), pack-reused 80\u001b[K\n",
            "Receiving objects: 100% (106/106), 42.79 MiB | 31.23 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWchHumVl8KQ"
      },
      "source": [
        "## Exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFEZkXUvrc8Y"
      },
      "source": [
        "!pip install rasterio\r\n",
        "!pip install geopandas\r\n",
        "!pip install earthpy\r\n",
        "!pip install rasterstats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5PrMZaqTOBA"
      },
      "source": [
        "import os\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import rasterio as rio\r\n",
        "from rasterio.plot import plotting_extent\r\n",
        "import geopandas as gpd\r\n",
        "import earthpy as et\r\n",
        "import earthpy.spatial as es\r\n",
        "import earthpy.plot as ep\r\n",
        "\r\n",
        "import rasterstats\r\n",
        "\r\n",
        "\r\n",
        "import sklearn\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFyRDu9MTS_I"
      },
      "source": [
        "### Plotting the RGB image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twDp7hueTQn4"
      },
      "source": [
        "#From: https://earthpy.readthedocs.io/en/latest/gallery_vignettes/plot_rgb.html\r\n",
        "\r\n",
        "#fetches the iamges at 30m excluding the panchromatic and cirrus \r\n",
        "landsat_bands_data_path = \"/content/classifying_satellite_imagery_in_R/data/band*[1-7]*.tif\"\r\n",
        "\r\n",
        "stack_band_paths = glob(landsat_bands_data_path)\r\n",
        "stack_band_paths.sort()\r\n",
        "\r\n",
        "#resorting because of the band names \r\n",
        "stack_band_paths_sorted = [stack_band_paths[i] for i in [0,3,4,5,6,7,8]]\r\n",
        "\r\n",
        "#print(stack_band_paths)\r\n",
        "#print(stack_band_paths_sorted)\r\n",
        "\r\n",
        "# Create image stack and apply nodata value for Landsat\r\n",
        "arr_st, meta = es.stack(stack_band_paths_sorted, nodata=-9999)\r\n",
        "\r\n",
        "#From: https://earthpy.readthedocs.io/en/latest/gallery_vignettes/plot_rgb.html\r\n",
        "\r\n",
        "# Create figure with one plot\r\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\r\n",
        "\r\n",
        "ep.plot_rgb(arr_st, rgb=(3, 2, 1), ax=ax, title=\"Landsat 8 RGB Image\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmWdwha5TYeQ"
      },
      "source": [
        "### Loading the points and plotting the overal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "thlT89mUTW08",
        "outputId": "d99c0bd6-63a1-40ea-f056-90da0495e997"
      },
      "source": [
        "#Loading and reprojecting\r\n",
        "sample_shp = gpd.read_file('/content/classifying_satellite_imagery_in_R/data/calgary_trainingPoints.shp')\r\n",
        "shp_prj = sample_shp.to_crs(epsg=32612)\r\n",
        "#shp_prj.crs\r\n",
        "shp_prj"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>id</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clouds</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POINT (273026.189 5668459.275)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>clouds</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POINT (274910.786 5668286.479)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>clouds</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POINT (275346.879 5668903.405)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clouds</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POINT (275993.389 5668347.157)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>clouds</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POINT (275833.212 5668744.188)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>water</td>\n",
              "      <td>4.0</td>\n",
              "      <td>POINT (289879.993 5639054.215)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>water</td>\n",
              "      <td>4.0</td>\n",
              "      <td>POINT (290748.279 5637522.819)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>water</td>\n",
              "      <td>4.0</td>\n",
              "      <td>POINT (290663.551 5637559.526)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>water</td>\n",
              "      <td>4.0</td>\n",
              "      <td>POINT (290709.630 5637615.015)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>water</td>\n",
              "      <td>4.0</td>\n",
              "      <td>POINT (290734.930 5637529.147)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>701 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      class   id                        geometry\n",
              "0    clouds  1.0  POINT (273026.189 5668459.275)\n",
              "1    clouds  1.0  POINT (274910.786 5668286.479)\n",
              "2    clouds  1.0  POINT (275346.879 5668903.405)\n",
              "3    clouds  1.0  POINT (275993.389 5668347.157)\n",
              "4    clouds  1.0  POINT (275833.212 5668744.188)\n",
              "..      ...  ...                             ...\n",
              "696   water  4.0  POINT (289879.993 5639054.215)\n",
              "697   water  4.0  POINT (290748.279 5637522.819)\n",
              "698   water  4.0  POINT (290663.551 5637559.526)\n",
              "699   water  4.0  POINT (290709.630 5637615.015)\n",
              "700   water  4.0  POINT (290734.930 5637529.147)\n",
              "\n",
              "[701 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7O1eoHWTdb8"
      },
      "source": [
        "#we have to fetch the extent using the rasterio package\r\n",
        "with rio.open('/content/classifying_satellite_imagery_in_R/data/band1.tif') as image_src:\r\n",
        "  img_data = image_src.read()\r\n",
        "\r\n",
        "  img_extent = plotting_extent(image_src)\r\n",
        "  \r\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\r\n",
        "\r\n",
        "ep.plot_rgb(arr_st, rgb=(3, 2, 1), ax=ax, title=\"Landsat 8 RGB Image\",extent=(img_extent))\r\n",
        "shp_prj.plot(ax=ax)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiDh5q2UThXS"
      },
      "source": [
        "## Extracting the values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgXsPK_7TjEo",
        "outputId": "dfb6e071-6ec7-4c3f-9727-1c525ccccc78"
      },
      "source": [
        "#first we save everything (the stacked raster and the projected shapefile to a directory)\r\n",
        "!mkdir outputs\r\n",
        "\r\n",
        "#saving\r\n",
        "shp_prj.to_file('/content/outputs/sample_loc.shp')\r\n",
        "es.stack(stack_band_paths_sorted, out_path='/content/outputs/Landsat.tif') #fails because of uint16 if we add the thermals\r\n",
        "\r\n",
        "#other alternatives here: https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\r\n",
        "\r\n",
        "from rasterstats import point_query\r\n",
        "\r\n",
        "for i in range(1,8):\r\n",
        "  #pt_query = point_query('/content/outputs/sample_loc.shp',i)\r\n",
        "  #print(pt_query[0])\r\n",
        "\r\n",
        "  #querying the data\r\n",
        "  pt_query = point_query('/content/outputs/sample_loc.shp','/content/outputs/Landsat.tif',band=i)\r\n",
        "  #print(i)\r\n",
        "  #print(pt_query[0])\r\n",
        "\r\n",
        "  band_nr = \"B\"+str(i)\r\n",
        "  print('Processing:',band_nr)\r\n",
        "\r\n",
        "  #adding to the pandas\r\n",
        "  shp_prj[band_nr]=pt_query"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘outputs’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n",
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Unable to open EPSG support file gcs.csv.  Try setting the GDAL_DATA environment variable to point to the directory containing EPSG csv files.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing: B6\n",
            "Processing: B7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFqjIbD3TzeE"
      },
      "source": [
        "#Setting up for AutoGluon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0bC2HTJVjkK"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lcmVMvxTwpU"
      },
      "source": [
        "#removing NA from the datasets\r\n",
        "test_data = shp_prj\r\n",
        "test_data = test_data.dropna(0) #there is one row somewhere with an NA that causes errors, se we just remove it\r\n",
        "\r\n",
        "#selecting data and conerting to category\r\n",
        "df_x = test_data[[\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\"]]\r\n",
        "df_y = test_data[['class']].astype('category')\r\n",
        "\r\n",
        "#using Sklearn data splitter\r\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df_x, df_y, random_state=42,test_size=0.3) #.7/.3 split\r\n",
        "\r\n",
        "#appending the data into the same table\r\n",
        "df_train = pd.concat([X_train,y_train],axis=1)\r\n",
        "df_test = pd.concat([X_test,y_test],axis=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzWhcrKXT9-s",
        "outputId": "d9044e7d-e7d6-42b7-fab0-a1d272e393b2"
      },
      "source": [
        "auto_glu = task.fit(train_data=df_train,\r\n",
        "                    label='class',\r\n",
        "                    time_limits=180,\r\n",
        "                    num_bagging_folds=5,num_bagging_sets=1,\r\n",
        "                    hyperparameters='light',\r\n",
        "                    random_seed=42)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No output_directory specified. Models will be saved in: AutogluonModels/ag-20210217_234259/\n",
            "Beginning AutoGluon training ... Time limit = 180s\n",
            "AutoGluon will save models to AutogluonModels/ag-20210217_234259/\n",
            "AutoGluon Version:  0.0.15\n",
            "Train Data Rows:    490\n",
            "Train Data Columns: 7\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == category).\n",
            "\t4 unique label values:  ['undeveloped', 'water', 'developed', 'clouds']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 4\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12473.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 7 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 7 | ['B1', 'B2', 'B3', 'B4', 'B5', ...]\n",
            "\t0.0s = Fit runtime\n",
            "\t7 features in original data used to generate 7 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
            "Fitting model: NeuralNetClassifier_STACKER_l0 ... Training model for up to 179.91s of the 179.91s of remaining time.\n",
            "\t0.9327\t = Validation accuracy score\n",
            "\t9.51s\t = Training runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestClassifierGini_STACKER_l0 ... Training model for up to 170.3s of the 170.29s of remaining time.\n",
            "\t0.9245\t = Validation accuracy score\n",
            "\t3.46s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: RandomForestClassifierEntr_STACKER_l0 ... Training model for up to 166.25s of the 166.25s of remaining time.\n",
            "\t0.9224\t = Validation accuracy score\n",
            "\t3.54s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ... Training model for up to 162.13s of the 162.12s of remaining time.\n",
            "\t0.9265\t = Validation accuracy score\n",
            "\t2.51s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ... Training model for up to 159.0s of the 159.0s of remaining time.\n",
            "\t0.9245\t = Validation accuracy score\n",
            "\t2.53s\t = Training runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifier_STACKER_l0 ... Training model for up to 155.86s of the 155.86s of remaining time.\n",
            "\t0.9367\t = Validation accuracy score\n",
            "\t1.24s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifierXT_STACKER_l0 ... Training model for up to 154.55s of the 154.55s of remaining time.\n",
            "\t0.9388\t = Validation accuracy score\n",
            "\t0.82s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: CatboostClassifier_STACKER_l0 ... Training model for up to 153.69s of the 153.68s of remaining time.\n",
            "\t0.9429\t = Validation accuracy score\n",
            "\t5.71s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMClassifierCustom_STACKER_l0 ... Training model for up to 147.95s of the 147.95s of remaining time.\n",
            "\t0.9245\t = Validation accuracy score\n",
            "\t3.87s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: weighted_ensemble_k0_l1 ... Training model for up to 179.91s of the 143.89s of remaining time.\n",
            "\t0.9429\t = Validation accuracy score\n",
            "\t0.27s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 36.41s ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nhDfAhEWiBb",
        "outputId": "680a11a8-4c8a-4972-f8bb-0960de5bc6be"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "print(\"Validation accuracy score\", sklearn.metrics.accuracy_score(y_test, auto_glu.predict(df_test)))\r\n",
        "\r\n",
        "print(\"Validation kappa accuracy score\", sklearn.metrics.cohen_kappa_score(y_test, auto_glu.predict(df_test)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy score 0.9523809523809523\n",
            "Validation kappa accuracy score 0.9365252085600291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX1k3gfJYDbf"
      },
      "source": [
        "#Predicting to the raster\r\n",
        "\r\n",
        "- In general: Convert the multy-layer raster object to a \"table format\", apply the model and reconstruct the raster. \r\n",
        "\r\n",
        "- (Optional) This procedure above allows me to process in data chunks and to avoid going out of memory on the google colab\r\n",
        "\r\n",
        "PS: probably someone could do this better but i don't care"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBtxvpi3YGax",
        "outputId": "fd109436-9aa2-433d-84fd-dfc386f7bdd9"
      },
      "source": [
        "!pip install pyrsgis\r\n",
        "from pyrsgis.convert import changeDimension\r\n",
        "from pyrsgis import raster\r\n",
        "import rasterio\r\n",
        "import pyproj\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "#lading the landsat data \r\n",
        "ds1, bands = raster.read('/content/outputs/Landsat.tif')\r\n",
        "\r\n",
        "print(ds1)\r\n",
        "print(bands.shape) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyrsgis\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/73/1d57263ce7780cec74cf2e7c6dbe53e840521724a131900c5b28ad05d61f/pyrsgis-0.3.3-py3-none-any.whl\n",
            "Installing collected packages: pyrsgis\n",
            "Successfully installed pyrsgis-0.3.3\n",
            "Warning! matplotlib_scalebar library not found. You may not be able to export map directly.\n",
            "<pyrsgis.raster.createDS object at 0x7fc81e6aca58>\n",
            "(7, 1413, 1121)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/osgeo/gdal.py:112: DeprecationWarning: gdal.py was placed in a namespace, it is now available as osgeo.gdal\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgtw-I8WY0da",
        "outputId": "fa014443-5d8a-4c59-b4aa-f4a68a7bc1dd"
      },
      "source": [
        "#creates a np with 7 columns anx NxM rows (and also its tranposed)\r\n",
        "\r\n",
        "bandByPixel = changeDimension(bands) #we have to devide all values by 10k - its a conversion from bits to reflectances\r\n",
        "bandByPixel_t = np.transpose(bandByPixel)\r\n",
        "\r\n",
        "print(bandByPixel.shape)\r\n",
        "print(bandByPixel_t.shape)\r\n",
        "\r\n",
        "pd_bandByPixel = pd.DataFrame(data=bandByPixel,columns=[\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\"])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1583973, 7)\n",
            "(7, 1583973)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywf8Wsy8Y6Dc"
      },
      "source": [
        "## Prediction time "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ZC6XOqY2mS",
        "outputId": "d2e6aac2-172f-4395-afb4-eef09e1de624"
      },
      "source": [
        "y_pred = auto_glu.predict(pd_bandByPixel)\r\n",
        "y_pred\r\n",
        "\r\n",
        "#but the outputs are strings, so they need to be integers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['water', 'water', 'water', ..., 'water', 'water', 'water'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQqTETCcZH-X",
        "outputId": "f54abc58-8a36-4725-99c6-b2167b28aa70"
      },
      "source": [
        "#checking the clases\r\n",
        "shp_prj['class'].unique()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['clouds', 'developed', 'undeveloped', 'water'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llC_dCUlZLCO"
      },
      "source": [
        "#lazy but i don't care:\r\n",
        "y_pred_num = np.where(y_pred=='water', 0, y_pred) \r\n",
        "y_pred_num = np.where(y_pred_num=='undeveloped', 1, y_pred_num) \r\n",
        "y_pred_num = np.where(y_pred_num=='developed', 2, y_pred_num) \r\n",
        "y_pred_num = np.where(y_pred_num=='clouds', 3, y_pred_num)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_4vGms3ZNpy",
        "outputId": "412a90a8-81db-4500-fcb1-0ee292d4f3c5"
      },
      "source": [
        "#rebuilds the raster from the table we used before\r\n",
        "y_pred_np = np.reshape(y_pred_num,(ds1.RasterYSize,ds1.RasterXSize))\r\n",
        "y_pred_np.shape\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1413, 1121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfwg1EVpZPkb"
      },
      "source": [
        "#exports the data to our work space\r\n",
        "raster.export(y_pred_np, ds1, '/content/outputs/Landsat_Class_AutoGluon.tif', dtype='int') "
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}